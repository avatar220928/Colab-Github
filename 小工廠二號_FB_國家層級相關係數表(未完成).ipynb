{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avatar220928/Colab-Github/blob/material/%E5%B0%8F%E5%B7%A5%E5%BB%A0%E4%BA%8C%E8%99%9F_FB_%E5%9C%8B%E5%AE%B6%E5%B1%A4%E7%B4%9A%E7%9B%B8%E9%97%9C%E4%BF%82%E6%95%B8%E8%A1%A8(%E6%9C%AA%E5%AE%8C%E6%88%90).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **引入需要的套件**"
      ],
      "metadata": {
        "id": "diJcLkuE6YAa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OU4bjGaiAexe",
        "outputId": "4deaea1d-a760-4ebf-cc47-0ad70c3a2a7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns',100)\n",
        "pd.set_option('display.max_rows',20)\n",
        "pd.set_option('max_colwidth',1000)\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import seaborn as sns\n",
        "from scipy.stats.stats import pearsonr\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import datasets\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK7IDeTxAkT_",
        "outputId": "03884502-d8d3-4a45-a6aa-06f1626fcf69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "#讀兩份FB資料\n",
        "read_file_1 = '/content/drive/MyDrive/mobility移動資料/FB/movement-range-2022-03-19.txt'\n",
        "read_file_2 = '/content/drive/MyDrive/mobility移動資料/FB/movement-range-data-2020-03-01--2020-12-31.txt'\n",
        "\n",
        "#讀成dataframe\n",
        "df_2021=pd.read_table(read_file_1)\n",
        "df_2020=pd.read_table(read_file_2)\n",
        "\n",
        "#黏起來\n",
        "df_1=df_2020.append(df_2021)\n",
        "df_1.set_index(pd.to_datetime(df_1['ds'],format='%Y-%m-%d'),inplace=True)\n",
        "# print(df_1.head(-5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **def: 刪除google sheet裡的nan值**"
      ],
      "metadata": {
        "id": "saQS3FS0JQPP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AxHJ1jNPLQN9"
      },
      "outputs": [],
      "source": [
        "def deletenan (sheets,a):\n",
        "  A = sheets.col_values(a)\n",
        "  #print(A)\n",
        "  country_google_name = A.copy() #A是google_name的複製版\n",
        "  for i in range(len(A)):\n",
        "    if A[i]== '':\n",
        "      country_google_name.remove(A[i])\n",
        "  # print(country_google_name)\n",
        "  return country_google_name"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **def: 篩選case資料中所需的國家**"
      ],
      "metadata": {
        "id": "ZjHm232zNZR7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lXsCJO7WfrsD"
      },
      "outputs": [],
      "source": [
        "def choose_case(a,case_data,country_test):\n",
        "  case_data_new=case_data[case_data[ 'location' ]==country_test[a]] #篩選case國家\n",
        "  return(case_data_new)\n",
        "  print('成功2!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **def: 篩選FB資料中所需的國家**"
      ],
      "metadata": {
        "id": "fNLd6RrqNj10"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "315nlLiGWiz_"
      },
      "outputs": [],
      "source": [
        "def choose_FB(a,FB_data,country_name):\n",
        "  \n",
        "  sub_region_set=FB_data[FB_data['country']==country_name[a]] #篩選FB國家\n",
        "  sub_region_set=set(sub_region_set['polygon_name'])\n",
        "  sub_region_list=list(sub_region_set)\n",
        "  sub_region_list_1 = [str(x) for x in sub_region_list]\n",
        "  sub_region_list_2 = [x for x in sub_region_list_1 if x != 'nan']\n",
        "  # print('成功!')\n",
        "  # print(sub_region_list_2)\n",
        "  return(sub_region_list_2)\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **def: 轉換timestamp變成字串**"
      ],
      "metadata": {
        "id": "OtGetpEWNn0z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cUMVmBhtgLGO"
      },
      "outputs": [],
      "source": [
        "def timestamp2string(a):\n",
        "  #a = a.to_pydatetime()\n",
        "  str1 = a.strftime('%Y-%m-%d')\n",
        "  return str1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXAxslnR24jO"
      },
      "source": [
        "# **def: 切開日期list、指定日期**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "85Rd3-H8K3fw"
      },
      "outputs": [],
      "source": [
        "def split_list(date, n, n_2):\n",
        "  a = 0\n",
        "  if n[0]!= 1:\n",
        "    for  i_6 in range(len(n_2)):\n",
        "      a = a + n[i_6]\n",
        "      yield date[a : a + n_2[i_6]]\n",
        "  else: \n",
        "      yield date[0 : 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O1nmhAnN3mQ"
      },
      "source": [
        "# **def: 計算FB movement和new case之間的相關係數**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SHATuum0AyB2"
      },
      "outputs": [],
      "source": [
        "all_case= pd.read_csv('/content/drive/MyDrive/mobility移動資料/all_cases/owid-covid-data.csv')\n",
        "\n",
        "def googlecorrtable(country_name, country_test):\n",
        "  for i in range(len(country_name)): #選fb國家(df_1是fb資料)\n",
        "    print('現在進入到這個國家: '+country_name[i])\n",
        "    if country_name[i]=='MAR':\n",
        "      pass\n",
        "    \n",
        "    else:\n",
        "      n = len(start_date[i])\n",
        "      A = pd.DataFrame(np.zeros((n,4)),columns=['n','place','Coefficient_of_Correlation','p-value'])\n",
        "      \n",
        "      \n",
        "      sub_region_list_2 = choose_FB(i,df_1,country_name) #FB資料篩選\n",
        "      # print(sub_region_list_2)\n",
        "      case_data_new = choose_case(i, all_case, country_test) #case篩選\n",
        "      case_data_new.set_index(pd.to_datetime(case_data_new['date'],format='%Y-%m-%d'),inplace=True)\n",
        "\n",
        "      for ii in range(3): #選fb國家的polygon取前3\n",
        "        \n",
        "        df_2 = df_1[df_1['polygon_name']==sub_region_list_2[ii]]\n",
        "        # temp = [] \n",
        "        # for i_2 in df_2:\n",
        "        #   if df_2['ds'][i_2] not in set(df_2['ds']):\n",
        "        #     value = df_2['all_day_bing_tiles_visited_relative_change'][i_2]\n",
        "        #     temp.append(value)\n",
        "        temp = df_2.copy()\n",
        "        temp.set_index(pd.to_datetime(temp['ds'],format='%Y-%m-%d'),inplace=True)\n",
        "        corr=[]\n",
        "        p=[]\n",
        "        FB_mobility_sum = pd.DataFrame()\n",
        "        for iii in range(len(start_date[i])):  #這個迴圈負責把dataframe分解、重排\n",
        "\n",
        "          temp__= temp[temp[\"ds\"].between(start_date[i][iii],end_date[i][iii])]\n",
        "          FB_mobility_sum = pd.concat([FB_mobility_sum, temp__['all_day_bing_tiles_visited_relative_change']],axis=1)\n",
        "          # print(FB_mobility_sum)\n",
        "          # print('--------------------------------------------')\n",
        "      a=[]\n",
        "      for b in range(0,len(FB_mobility_sum.columns),len(start_date[i])):\n",
        "        a.append(b)\n",
        "      aa=a.copy()\n",
        "      while (len(a)<len(FB_mobility_sum.columns)):\n",
        "        aa = [x+1 for x in aa]\n",
        "        a+=aa\n",
        "        # print(a)\n",
        "\n",
        "      FB_mobility_sum_rearrange = FB_mobility_sum.iloc[:,a]\n",
        "      # print('FB_mobility_sum_rearrange在這邊')\n",
        "      # print(FB_mobility_sum_rearrange)\n",
        "      c=0\n",
        "\n",
        "      for iiii in range(len(start_date[i])):\n",
        "        A['n'][iiii] = str(iiii+1)\n",
        "        TW_case = case_data_new[case_data_new[\"date\"].between(start_date[i][iiii],end_date[i][iiii])]\n",
        "        FB_mobility_sum_new = FB_mobility_sum_rearrange.iloc[:,int(c):int(c)+3]\n",
        "        # print(FB_mobility_sum_new)\n",
        "        FB_mobility_sum_mean=FB_mobility_sum_new.mean(skipna=True,axis=1)\n",
        "        # print('取完平均',FB_mobility_sum_mean)\n",
        "        FB_mean = FB_mobility_sum_mean.dropna()\n",
        "       \n",
        "        # FB_mean.index = (pd.to_datetime(temp['ds'],format='%Y-%m-%d'),inplace=True)\n",
        "        # idx = pd.Index(FB_mean)\n",
        "        # print(idx)\n",
        "        # FB_mean = FB_mean.index.drop_duplicates(subset=['ds'])\n",
        "        # res = []\n",
        "        # for i_2 in FB_mean:\n",
        "        #   if i_2 not in FB_mean:\n",
        "        #     value = \n",
        "        #     res.append(i)\n",
        "\n",
        "        # print(FB_mean['ds'])\n",
        "        \n",
        "        aa = FB_mean\n",
        "        bb = TW_case['new_cases']\n",
        "        # print(np.isnan(aa))\n",
        "        # print(np.isnan(bb))\n",
        "        print(type(aa))\n",
        "\n",
        "        check_for_nan_1 = aa.isnull().any().any()\n",
        "        # print ('FB_mean有nan嗎?'+ str(check_for_nan_1))\n",
        "\n",
        "        check_for_nan_2 = bb.isnull().any().any()\n",
        "        # print ('case number有nan嗎?'+ str(check_for_nan_2))\n",
        "\n",
        "        if str(check_for_nan_1)=='True' or str(check_for_nan_2)=='True': \n",
        "          nansite_1 = aa.index[np.where(np.isnan(aa))]  #找fb的nan\n",
        "          nansite_2 = bb.index[np.where(np.isnan(bb))]  #找case的nan\n",
        "          print(timestamp2string(nansite_1))\n",
        "          print(timestamp2string(nansite_2))\n",
        "          for cc in range(len(nansite_2)):\n",
        "            aa = aa.drop(pd.to_datetime(timestamp2string(nansite_2)[cc]))\n",
        "          for dd in range(len(nansite_1)):\n",
        "            bb = bb.drop(pd.to_datetime(timestamp2string(nansite_1)[dd]))\n",
        "\n",
        "          bb = bb[bb.notna()]\n",
        "          aa = aa[aa.notna()]\n",
        "\n",
        "        # print(len(aa))\n",
        "        # print(len(bb))\n",
        "        # print(aa)\n",
        "        # print(bb)\n",
        "\n",
        "        if (len(aa)==len(bb)) and (len(aa)!=0):\n",
        "          ans = pearsonr(aa, bb)\n",
        "          corr.append(ans[0])\n",
        "          p.append(ans[1])\n",
        "          \n",
        "        else:\n",
        "          corr.append(-99)\n",
        "          p.append(-99)\n",
        "        print(corr)\n",
        "\n",
        "        # print(FB_mean)\n",
        "        # print(TW_case['new_cases'])\n",
        "        # print(len(TW_case['new_cases']))\n",
        "        # print(len(FB_mean))\n",
        "        #print(sub_region_list_2[ii])\n",
        "\n",
        "        # if len(aa) == len(bb):\n",
        "        #   ans = pearsonr(aa, bb)\n",
        "        # # print(ans)\n",
        "        # corr.append(ans[0])\n",
        "        # p.append(ans[1])\n",
        "        \n",
        "\n",
        "        # FB_mobility_sum.drop(FB_mobility_sum.index,inplace=True)\n",
        "        c=c+3\n",
        "      A['Coefficient_of_Correlation'] = corr\n",
        "      A['p-value'] = p\n",
        "      A['place']=country_name[i]+'_FB'\n",
        "      # print(A)\n",
        "      A.to_csv(country_name[i]+'_FB_相關係數.csv',index=False)\n",
        "        \n",
        "      \n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "S6O21DoxfZUq",
        "outputId": "309097bb-345f-4ac9-dd8b-a6dac8c80fda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "現在進入到這個國家: GBR\n",
            "<class 'pandas.core.series.Series'>\n",
            "[-99]\n",
            "<class 'pandas.core.series.Series'>\n",
            "[-99, -99]\n",
            "<class 'pandas.core.series.Series'>\n",
            "Index([], dtype='object')\n",
            "Index(['2021-04-09'], dtype='object', name='date')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-0f01530286e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0mcountry_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#case number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0mgooglecorrtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcountry_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-65804633dce5>\u001b[0m in \u001b[0;36mgooglecorrtable\u001b[0;34m(country_name, country_test)\u001b[0m\n\u001b[1;32m     89\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestamp2string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnansite_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mcc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnansite_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0maa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestamp2string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnansite_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mdd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnansite_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestamp2string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnansite_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4684\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4685\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4686\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4687\u001b[0m         )\n\u001b[1;32m   4688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4150\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4185\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6017\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6019\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"[Timestamp('2021-04-09 00:00:00')] not found in axis\""
          ]
        }
      ],
      "source": [
        "import gspread\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "urls='https://docs.google.com/spreadsheets/d/1Jxcr8PvzqyEOa3DDT7wh9sBgJDGoDTqqLvDoT1r9R10/edit#gid=337413139'\n",
        "\n",
        "sheet_name = ['Europe', 'North America','South America','Asia','Africa','Oceania'] \n",
        "country_mobility_1 = gc.open_by_url(urls)\n",
        "\n",
        "for i_1 in range(len(sheet_name)):\n",
        "  sheet = country_mobility_1.worksheet(sheet_name[i_1])  #讀取國家全名的全部sheet\n",
        "\n",
        "  #消除nan\n",
        "\n",
        "  data=[]\n",
        "  col=[ii for ii in range(1,7)]\n",
        "\n",
        "  for b in col:\n",
        "    c = deletenan(sheet,a = b)  #去除每條column的nan值\n",
        "    data.append(c)\n",
        "\n",
        "  for bb in range(len(data)):\n",
        "\n",
        "    int_n = list(map(int, data[3]))  #讓list裡的str變成int\n",
        "    int_n_2 = int_n.copy()\n",
        "    \n",
        "    int_n.insert(0, 0)\n",
        "\n",
        "  start_date = list(split_list(data[4], int_n, int_n_2))\n",
        "  end_date = list(split_list(data[5], int_n, int_n_2))\n",
        "\n",
        "  country_name = data[2] #fb mobility\n",
        "  country_test = data[0] #case number\n",
        "\n",
        "  googlecorrtable(country_name, country_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aw1LNrlKPPGZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "小工廠二號: FB_國家層級相關係數表(未完成).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNDYmAcE3/ky9yrbP9NJ+2D",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}